---
title: "ComptoxR: An R Package to Retrieve Compound Information from US EPA Products and APIs for Rapid Chemical Hazard, Risk, Toxicological Evaluation and Screening"

authors:
  - name: Sean Thimons
    affiliations: 
    - ref: orise
    orcid: 0000-0002-3736-2529
    corresponding: true
    email: thimons.sean@epa.gov
  - name: Grace Patlewicz
    affiliations: 
    - ref: epa
    orcid: 0000-0003-3863-9689
  - name: Antony Williams
    affiliations: 
    - ref: epa
    orcid: 0000-0002-2668-4821
  
affiliations:
  - id: orise
    name: Oak Ridge Institute for Science Education
    city: Oak Ridge
    state: TN
    country: USA
  - id: epa
    name: U.S. Environmental Protection Agency, Office of Research & Development, Center for Computational Toxicology & Exposure (CCTE)
    city: Research Triangle Park
    state: NC 
    country: USA

filters:
  - authors-block
        
prefer-html: true

format:
  #native: default
  docx: default
  html: default
  pdf:
    keep-tex: true
  
editor: visual
execute: 
  keep-md: false
  warning: false
  error: false
  message: false
  cache: true
editor_options: 
  chunk_output_type: inline
---


```{r}
#| label: load-packages
#| include: false
#| eval: true
#| echo: false

library(ComptoxR)
library(dplyr)
library(stringr)
library(knitr)
library(kableExtra)
library(flextable)
library(tidyr)
library(purrr)

comptox_server(server = 1)

prod_volume <- readRDS('prod_volume.Rds')

```

## Abstract

The CompTox Chemical Dashboard (CCD) has gone through several improvements over the past few years, including batch downloading and inclusion of larger data sets for user analysis. However, query times for the batch download process can be long for larger volumes of compound requests. Users can also selectively request data on a very granular basis through the website, but the requesting all of an endpoint (e.g.: 'fate and transport' data) for several compounds can be time-consuming. `ComptoxR` aims to strike a balance between granular and comprehensive data harvesting.

We developed the open-source R package `ComptoxR` that allows users to automatically query the underlying databases that supports CCD and other products from USEPA, extract out the data into an R object, and perform several analyses on the query. We provide several useful functions for querying specific endpoints for compounds such as physio-chemical properties, model predictions from EPI Suite, ChemAxon, TEST, and OPERA QSAR models, hazard data. We also provide native R implementations of the Hazard Comparison and ToxPrint Chemotypes Exploring Chemical Feature Enrichments modules from USEPA's Cheminformatics and GenRA (Generalized Read-Across) tools.

`ComptoxR` follows the FAIR (findability, accessibility, interoperability, and reusability) principle for the data returned from queries, aiming to facilitate rapid chemical screening for hazard, risk, and toxicological characterization for a variety of end-users. Quality-control, curation level, and citation data is also generally available for compound queries, a feature not readily available in other packages.

## Introduction

### Implementation and Design Details

`ComptoxR` is written in R and relies upon several packages to function effectively. Several other packages were used for operation speed or because they offered time-saving implementations. Functions are grouped by .R file bearing the same name. An associated documentation file is generated when building the package that an end-user can readily access, along with several vignettes detailing suggested use-cases.

Most functions that work to retrieve data on a compound are also implemented in a 'batch' function to reduce query times. Lists of compounds that number over 200 will automatically be batched to accommodate API throughput limits and seamlessly assemble the data into a single dataframe object. Typically, any function will use a RESTful GET request for a single compound, and a POST request for everything else.

When possible, the data returned is returned as-is from the API. We feel this an appropriate design choice as this reduces design debt that comes with software development and allows us to accommodate future additions or changes to our data sources. Some functions (e.g.: `ct_details()` offer different subsets of data from the endpoint. Where this is an option, the default option is specified to the user, with optional arguments detailed in the appropriate help file.

### Data Sources

`ComptoxR` comes with several existing data sources packaged within for analysis and comparison purposes. Some are required, as they function as "dictionary" files for searching purposes, while others (i.e.: `dtx_list`) are examples that can be used to demonstrate abilities. There are four main API endpoints that `ComptoxR` targets: three public-facing APIs from US EPA (CCD, GenRA, and CTS) and one for PubChem to retrieve Globally Harmonized System of Classification and Labeling of Chemicals (GHS) data through the `webchem` package.

## Installation and initial setup

The CCD API requires an API token for authentication. After requesting one, create an environmental variable as detailed below. A user can test if their key is present by running the `ct_api_key()` function. A restart of the R session may be needed. Upon loading the package, a user must set the server pathway using the `comptox_server()` function. This is designed to accommodate upstream shifts in server URLS, or allow access to private servers when available. When running the function, the base URL of the request will be output to the console.

```{r}
#| label: installation
#| eval: false
#| include: true
#| echo: true

library(ComptoxR)

#Sys.setenv('ccte_api_key' = [TOKEN HERE])

ct_api_key()

comptox_server()

```

## Use cases

### Querying names, supported identifiers, and details of compounds

Often, a user needs to find a particular compound, but may only have a portion of a name or is using an identifier such as a CAS-RN or InChIKey string. The `ct_name()` function provides several ways to search for compounds for their preferred name and DTXSID. Three search parameters (`starts-with`, `equals`, `substring`) offer different ways of searching for compounds.

```{r}
#| label: name-search1
#| eval: true
#| include: true

#String search
ct_name('atraz', param = 'start-with') %>%
  select(searchName, rank, preferredName) %>%
  head(n = 10)
```

```{r}
#| eval: true
#| include: true
#| label: name-search2

#InChlKey search
ct_name('MXWJVTOOROXGIU', param = 'start-with') %>%
  select(searchValue, rank, preferredName) %>%
  head(n = 10)
```

```{r}
#| label: name-search3
#| eval: true
#| include: true

#CAS_RN search
ct_name('1912-24', param = 'contain') %>%
  select(searchValue, preferredName, casrn)
```

Additionally, a function to return all verified synonyms of a given compound is available. A user may find this useful, as old CAS-RNs, product names, or variations on proper names can be returned.

```{r}
#| label: syno-search
#| eval: true
#| include: true

ct_synonym(query = 'DTXSID7020182') %>%
  head(n = 10)
```

After a compound's DTXSID has been located, a user may want to inquire on various details for the compound. The `ct_details()` function provides an executive summary of a compound, with over sixty variables being available. Here, a user can easily ascertain important details about the compound in question, ranging from the quality of curation about a compound, the number of active assays in the ToxCast assay program, to knowing the monoisotopic mass, molecular formula or SMILES string.

```{r}
#| label: detail-search
#| eval: true
#| include: false

df <- ct_details(dtx_list[1])

# A selection of the data available for the query

df %>%
  select(dtxsid,preferredName, smiles, molFormula, monoisotopicMass,toxcastSelect,octanolWaterPartition,qcLevelDesc) %>%
  glimpse()
```

### Querying for physio-chemical properties and environmental fate/ transport data

A common, initial step for hazard identification is screening by physio-chemical properties or potential longevity within a given environment. The function `ct_prop()` returns both experimental and predictive physical-chemical properties, with accompanying source documentation. Users can then filter or subset the data as appropriate.

```{r}
#| label: prop_search
#| eval: true
#| include: false
#| echo: true
#| tbl-cap: "Physio-chemical Properties for Perfluorooctanoic acid"

df <- ct_prop(query = dtx_list[1], debug = FALSE) 

```

```{r}
#| label: tbl-prop_search
#| eval: true
#| include: true
#| column: page
#| echo: false
#| tbl-cap: "Physio-chemical Properties for Perfluorooctanoic acid"

df <- df %>%
  select(name, value, source, propType, unit, dtxsid) %>% 
  group_by(name, propType) %>% 
  reframe(value = round(mean(value), 3), unit) %>%
  distinct(name, propType, value, unit) %>% 
  pivot_wider(., id_cols = c(name, unit), names_from = propType, values_from = value)

kable(df) %>% kable_styling(position = "center")
```

For environmental fate/ transport data, the `ct_env_fate()` function also returns experimental and predictive data where available.

```{r}
#| label: eft-search
#| eval: true
#| include: false
#| echo: true

df <- ct_env_fate(query = dtx_list[1], debug = FALSE) 

```

```{r}
#| label: tbl-eft-search
#| eval: true
#| include: true
#| echo: false
#| tbl-cap: 'Environmental Fate/ Transport Data for Perfluorooctanoic acid'
#| column: page

df <- df %>% 
  select(valueType, modelSource, unit, endpointName, resultValue) %>%
  group_by(endpointName, valueType) %>%
  summarize(value = round(mean(resultValue), 3), unit) %>%
  distinct(endpointName, valueType, value, unit) %>% 
  pivot_wider(., id_cols = c(endpointName, unit), names_from = valueType, values_from = value) 

kable(df) %>% kable_styling(position = "center")
```

### Hazard Comparison

Following the logic primarily outlined by @vegosen_2020, the `hc_table()` function is provided to compare a set of compounds across a multitude of endpoints. Each endpoint is binned into a range of categorical tiers ('VH', 'H', 'M', 'L', 'NA'). These tiers are based off of numerical data (e.g. LD50 values) and categorical data (e.g.: from GHS data). Within the `hc_table()` function, a number of other functions are called to retrieve data. Data is then aggregated and converted to a categorical value based on the criteria as detailed by @vegosen_2020.

In this implementation, we use a variation on the 'trumping' methodology. Briefly, we search for numerical, authoritative data sources as a primary search parameter. This entails experimental, historical data that has been curated by CCD. For compounds that are data-poor, we also search for GHS data for the relevant 'H codes' and across curated, aggregated lists (ECHA SVCH, IARC, OEHHA Prop 65) for hazard and risk classifications. Lists are pulled from CCD or directly from the parent agency's site, and stored as a RDS object. Since these do not (typically) contain numerical threshold data, we convert the ranged values of the from binning criteria into a median value and assign it the compound with the corresponding categorical classification. Finally, as a last resort we query against QSAR-based models (e.g.: TEST) and assign a categorical value from the prediction. We feel this is an appropriate workflow, as historical data and GHS rankings are based off of experimental data, while QSAR-based models are statistical extrapolations and subject to applicability domain restrictions.

Not included in the original implementation or the current hosted web-application, we include several endpoints that risk-assessors may find useful under the larger family of 'Safety'. Endpoints of 'Ignitability', 'RxnWater' (reaction with water), and 'SelfRxn' (self-reacting) were added and derived based off of physio-chemical properties (flash point, boiling point) and GHS 'H codes' classifications. We also opted to include a 'Mobility' endpoint under the 'Environmental Fate' family that incorporates ECHA's definitions of 'persistence, mobility and toxicity (PMT/vPvM)' compounds based off of the organic carbon-water coefficient, as this is a well-described property in the literature and able to be predicted by QSAR model.

The function `hc_table()` function has a number of useful arguments that may be of interest. While the `query` argument is required for live searching, the `archive` or `save` arguments are not. If on an initial query the 'save' argument is set to `TRUE`, the underlying data that is generated is saved in the local directory as an .Rds file. In parallel, the arguments `archive_string` and `save_string` allow the user to supply a custom string for a file name.

```{r}
#| label: hc-table1
#| eval: true
#| echo: true
#| output: false
df <- hc_table(query = dtx_list[c(1,7:10,29)], archive = T, save = F, save_string = 'hct_example_', archive_string = 'hct_example_')

```

```{r}
#| eval: true
#| echo: false
#| include: true
#| label: tbl-hc-table2

df_names <- ct_details(query = dtx_list[c(1,7:10,29)]) %>%
  select(dtxsid, preferredName)

df <- left_join(df, df_names, by = c("compound" = "dtxsid")) %>%
  relocate(preferredName, .after = compound)

df_tbl <- df %>% select('preferredName', !contains('_amount')) %>% 
  select(!compound)

```

{{< pagebreak >}}

```{r}
#| eval: true
#| echo: false
#| include: true
#| tbl-cap: 'Hazard Comparison'
#| label: tbl-hc-table3
#| column: page
 
df_tbl %>% 
  flextable() %>% 
  align(align = 'center', part = 'all') %>% 
  valign(j = 1, valign = 'bottom', part = 'header') %>%
  bg(bg = scales::col_factor(palette = 'YlOrRd', levels = c('L', 'M', 'H', 'VH'))) %>% 
  bg(j = 'preferredName', bg = 'white') %>% 
  rotate(., j = 2:17, align = 'bottom', rotation = 'btlr', part = 'header') %>% 
  add_header_row(., values = c(' ','Human Health Effects','Ecotoxicity','Safety','Env. Fate'), colwidths = c(1,8, 2, 3, 3)) %>% 
  rotate(., i = 1,rotation = 'lrtb', align = 'bottom', part = 'header') 
```

{{< pagebreak >}}

Data completeness functions are also able to be ran to better assess the relative quality of both the compounds and endpoints being assessed.

The 'compound coverage' score is an assessment of how many endpoints for each compound were able to be queried for, displayed as a fraction of 1.0 (analogous to 100%). Here, all compounds that were included in the initial query has at-least 50% of the endpoints represented (12 out of 16).

```{r}
#| label: hc-compound-coverage
#| eval: true
#| include: true

hc_cc <- hc_compound_coverage(table = df, ID = 'preferredName', suffix = '_amount')

```

```{r}
#| label: tbl-hc-compound-coverage
#| eval: true
#| tbl-cap: 'Compound coverage scores'
#| column: page

hc_cc %>%
  mutate(data_coverage = round(data_coverage, digits = 2)) %>%
  kable() %>% kable_styling(position = "center")
```

Conversely, the 'endpoint coverage' score returns the percentage of compounds being available per each endpoint. This table is critical to the ToxPi calculation, as it is responsible for the weighting parameter. By default, the weighting per each endpoint is defaulted to a '1.0' (i.e.: equal).

```{r}
#| label: hc-meta2
#| eval: true
#| echo: true

hc_endpoint_coverage(table = df, ID = 'preferredName', suffix = '_amount', filter = 0)
```

We recommend that a user run this function with an explicitly declared filter parameter for the score set to '0' to see all relative responses before selecting an appropriate cutoff value. Failing to explicitly specify a filter cutoff will default the value to '0.5'.

```{r}
#| label: tbl-bias
#| include: true
#| eval: true
#| echo: false
#| tbl-cap: 'Endpoint weighing for bias'
#| column: page

bias <- hc_endpoint_coverage(table = df, ID = 'preferredName', suffix = '_amount')

kable(bias) %>% kable_styling(position = "center")
```

After assessing the quality of data, a user may manually adjust the weight response per each endpoint via manual subsetting.

The helper `ct_archive()` function can be ran to load the data easily into local working memory for closer examination. If the such a file exists AND the 'archive' flag is set to true, the function uses the data to recreate the table, saving query request time. The underlying data structure unpacks to the global environment should a user want to examine the data further.

#### ToxPi Ranking

As detailed by @reif_2010, we have implemented the Toxicological Priority Index (ToxPi) scoring algorithm within this package. ToxPi relied upon weight-of-evidence to subjectively rank compounds across various domains yielding a unitless score.

For each endpoint from the hazard comparison table, the responses are scaled through a min-max normalization to \[0-1\] (Eq. 1). The score for each endpoint is then summed per compound, yielding a unitless score, where the higher score indicates higher, relative hazard and risk (Eq. 2).

$$x' =  \frac{x - min(x)}{max(x)- min(x)}$$ {#eq-single-score}

$$ToxPi =\sum_{1}^{I}*endpoint_i*weight_i + ... + \sum_{1}^{N}*endpoint_n*weight_n $$ {#eq-combined-score}

It should be noted that low performing (or compounds with a score of zero) compounds do **not** indicate a *lack* of associate hazard or risk, but rather a lack of information regarding these compounds.

Eq. 1 is detailed in the function `tp_single_score()`, where a single vector (e.g.: a single column from a data frame) is evaluated. An additional parameter (disabled by default) is also included, which 'backfills' any compound that has a zero for that endpoint to the specified number. This could be the lowest non-zero response, the average, or the max of each endpoint. We feel this is an important option that should be used with care, as it could adversely affect the conclusions a user may draw.

Eq. 2 is detailed in the function `tp_combined_score()`. Once a hazard comparison table has been generated, a user can request a relative prioritization based on the bias table. Should no bias table be specified, the function will proactively call the `hc_endpoint_coverage()` function with filter cutoff parameter specified to 0.1. The ellipse argument ( `â€¦` ) allows for the `back_fill` argument to be specified from the `tp_single_score()` function.

As an example, a subset from an included data set from the package (the list-object `dtx_list`) was used. An analysis of these compounds suggests that along the endpoints we have selected for (n = 12), Dazomet shows the highest relative risk, with (Z)-1,2-Dichloroethylene showing the lowest relative risk. This scoring is partially due to the amount of data being returned by each compound, with Dazomet having \~76% of the endpoints documented, and (Z)-1,2-Dichloroethylene having \~56% (see @tbl-hc-compound-coverage)

```{r}
#| label: tp
#| eval: true
#| include: true
#| column: page
#| echo: true

#Backfill with 50% of the lowest non-zero response

df_tp <- tp_combined_score(table = df, ID = 'preferredName', bias = bias, back_fill = 'half_min')

```

```{r}
#| label: tbl-tp
#| eval: true
#| include: true
#| echo: false
#| tbl-cap: 'ToxPi ranking'
#| column: page

df_tp %>% select(preferredName, score) %>% arrange(desc(score)) %>% kable() %>% kable_styling(position = "center")

```

If we were to re-run the analysis to *only* examine endpoints that all shared inclusive coverage of all of the compounds, the results are detailed below. Of interest, PFOA and BPA are raised in ranking while Benzene is dropped in ranking within the list, indicating some overlapping parameter that may be of interest in the right context. While we recognize that this subset of compounds is not a realistic comparison, it still outlines the useful and subjectiveness of using the ToxPi approach for prioritization.

```{r}
#| label: tp2
#| eval: true
#| include: true
#| echo: true
#| message: false
#| column: page

bias2 <- hc_endpoint_coverage(table = df, ID = 'preferredName', suffix = '_amount')

bias2$weight[bias2$score != 1] <- 0

df_tp2 <- tp_combined_score(table = df, ID = 'preferredName', bias = bias2, back_fill = 'half_min')
```

```{r}
#| label: tbl-tp2
#| eval: true
#| include: true
#| tbl-cap: 'Adjusted ToxPi ranking'
#| echo: false
#| message: false
#| column: page

df_tp2 %>% select(preferredName, score) %>% arrange(desc(score)) %>% kable() %>% kable_styling(position = "center")

```

### Generalized Read-Across (GenRA) and ToxPrint Enrichment

#### GenRA

Read-Across is an approach thoroughly documented in the literature (@patlewicz_2023) for extrapolating from a data-rich 'community' to data-poor 'individual' for predictive purposes. We offer the functionality available to the public found at <https://comptox.epa.gov/genra/> through this package for both single compound and batch-search functionality. We demonstrate here a typical workflow for using GenRA functions that would be analogous to the website experience.

##### Basic functionality

Like nearly all of the functions in this package, the starting point is a DTXSID for referencing a compound. Here, the DTXSID of Trimethylene glycol diacrylate is used. The other arguments are the fingerprint to find analogues by (Morgan \[default\], Torsion, ToxPrints, ToxCast, or ToxRef), filters to select the analogues by (compounds with or without data) and the number of analogs to return. In the example, we've used the ToxPrint, and requested 10 analogs. The first row is our searched compound, with the most similar compounds following, as described by the Jaccard similarity metric.

```{r}
#| label: genra-nn1
#| eval: true
#| include: true
#| echo: true

nn <- genra_nn(query = 'DTXSID2026107', fp = 'chm_mrgn', sel_by = 'tox_txrf', n = 10) %>% select(jaccard, name, dsstox_sid, casrn, mol_weight)

```

```{r}
#| label: tbl-genra-nn1
#| eval: true
#| include: true
#| echo: false
#| column: page
#| tbl-cap: 'Nearest neighbors for Tetraethylene glycol diacrylate'

kable(nn) %>% kable_styling(position = "center")
```

We then request the read-across using the next function, with similar arguments. A subset of the output is displayed below. GenRA returns data that belongs to either the ToxCast database or the ToxRef database, where it is grouped by study outcomes. The groups are:

-   chronic toxicity (CHR)

-   developmental toxicity (DEV)

-   developmental neurotoxicity (DNT)

-   multigenerational toxicity (MGR)

-   neurotoxicity (NEU)

-   reproductive toxicity (REP)

-   acute toxicity (ACU)

-   subacute toxicity (SAC)

-   subchronic toxicity (SUB)

-   other (OTH) toxicity testing studies

The column 'observation' details the queried compound's experimental results for that study design (if available), while the 'pred resp' is a predicted response (operating in a binary outcome).

```{r}
#| label: genra-ra
#| eval: true
#| include: false
#| echo: true
#| tbl-cap: "Read-Across Predictions for Tetraethylene glycol diacrylate"

ra <- genra_ra(query = 'DTXSID2026107', fp = 'chm_mrgn', sel_by = 'tox_txrf', n = 10)

ra <- ra %>% 
  select(name, effect_desc, observation, `pred resp`) %>%
  head(n = 4)
```

```{r}
#| label: tbl-genra-ra
#| eval: true
#| include: true
#| echo: false
#| tbl-cap: "Read-Across Predictions for Tetraethylene glycol diacrylate"
#| column: page

ra %>% kable() %>% kable_styling(position = "center")

```

Should a user desire it, a generic read-across function `read_across()` is provided to generate a prediction based on other data (e.g.: LD50 values) leveraging the GenRA's ability to fingerprint and find similar compounds, but currently relies on a user to provide the data.

#### ToxPrint Enrichment

Accurate depiction of chemicals is an important when operating in the cheminformatic space. As such, through both the CCD and GenRA, the ability to generate molecular fingerprints are provided. These fingerprints provide ways of describing complex 3D molecular features into a machine-readable format. One such method is the open-source XML-based 'Chemical Subgraphs and Reactions Markup Language (CSRML)' . As detailed by @yang_2015, these predefined molecular descriptors describe not only atom, bonds, electron systems, and molecules, but can also address issues such as topology or complex connectivity. Part of this novel method of describing compounds allows it to be extended to the extrapolation of *in-vitro* bioassays (\@wang_2019a). Here, we've reproduced the ToxPrint Enrichment workflow as found on the Cheminformatics web application (<https://www.epa.gov/chemical-research/cheminformatics>). A user can upload compounds, where the Toxprint fingerprints are retrieved by the GenRA service.

```{r}
#| label: toxprint1
#| eval: true
#| include: false
#| echo: true
#| results: hide
#| message: false

tp <- genra_batch_toxprint_tbl(query = dtx_list[c(1,7:10,29)])
```

```{r}
#| label: tbl-toxprint2
#| eval: true
#| include: false
#| echo: false
#| tbl-cap: 'ToxPrint Chemotype Enrichment Table'
#| column: page

tp2 <- left_join(tp, df_names, by = c('compound' = "dtxsid")) %>% select(-compound) %>% relocate(preferredName, .before = 'background control')

max_num <- max(tp2[,2:length(tp2)], na.rm = T) 
min_num <- min(tp2[,2:length(tp2)], na.rm = T) 


tp2 %>% 
  kable() %>% 
  kable_styling(position = "center", full_width = TRUE) %>%
  column_spec(2:length(tp2), 
              color = spec_color(min_num:max_num, 
                                 #end = 0.7,
                                 direction = -1, 
                                 option  = 'B'))
  

 
```

### Non-Targeted Analysis Compound Searching

To better assist in the hazard and risk management space, several functions are suggested for use. For searching by mass range or by a generic formula, the functions `ct_search_mass()` and `ct_search_formula()` are able to be leveraged. Users are able to then subset the resulting data to their liking.

```{r}
#| label: nta-search
#| eval: true
#| echo: true
#| include: true
#| message: false

#Searching by mass range
ct_search_mass(start = 413.9, end = 414) %>%
  select(dtxsid, preferredName, casrn, molFormula)


#Searching by molecular formula
ct_search_formula(query = 'C10H19O6PS2') %>%
  select(dtxsid, preferredName, casrn, averageMass, sourcesCount, toxcastSelect, qcLevel) %>%
  arrange(desc(sourcesCount))
```

### Case study implementation of package

To demonstrate the potential workflow of this package, we offer two hypothetical situations. In the first, risk assessors would be interested in the prioritization of sites that contain storage tanks of compounds. The hypothetical situation would revolve around selecting for highest threats to human and ecosystem, while taking into account site-specific volumes. For this, the risk assessors will incorporate various endpoints, including physio-chemical and environmental fate/ transport parameters to assess the potential if a tank were to be ruptured. The second scenario would examine an industrial waste stream being discharged into a river system. Risk assessors would examine two paradigms, one focused on acute threats to both human and ecosystem, the other on a long-term site surveillance for compounds known to be persistent, bioaccumulative, and have potential for chronic exposures.

#### Scenario 1: Storage tank prioritization

In scenario 1, a regulatory permit writer is looking to prioritize sites for enhanced risk management planning. A data set of the current listed compounds is assembled via the CCD's curated list. For compound production volumes, we've taken the average 2019 value from the 'Exposure - Production Volume' section from CCD for each compound (where available) as user-supplied data metric. This data is generated from the Chemical Data Reporting (CDR) Rule, issued under the Toxic Substances Control Act (TSCA), and represents the total volumes within the United States.

Next, the permit writer can utilize the `hc_table()` function and pass the list into it. The production volumes for each compound is joined against the table, and a bias table for weighing is created to work with the prioritization function. A 2x weight is applied against persistence, BAC, mobility factor, volume endpoints while other endpoints are rejected due to poor coverage. Finally, the ToxPi priortitization scheme is employed, with the top 10 compounds being returned. Not all compounds that were in this top 10 ranking had reported production volumes, suggesting that other endpoints should be considered and that total volumes within a given site may not be as important.

```{r}
#| label: scenario1_prep
#| eval: true
#| include: false
#| echo: false

#Pull list
#hs311 <- ct_list(list_name = 'CWA311HS')

#Create table
hs311_tbl <- hc_table(query = hs311$dtxsid, archive = T, save = F, save_string = 'cwa311hs_', archive_string = 'cwa311hs_')

#Focus on high volume compounds
hs311_tbl <- left_join(hs311_tbl, prod_volume, by = c("compound" = "dtxsid")) %>% filter(!is.na(volume_amount))

#Create bias table for different endpoints
bias <- hc_endpoint_coverage(table = hs311_tbl, ID = 'compound', suffix = '_amount', filter = 0.5)

#Adjustment to persistence, BAC, mobility, volume endpoint weighing

bias$weight[c(8,9,10,11)]<- 2

#Prioritization
hs311_tp <- tp_combined_score(table = hs311_tbl, ID = 'compound', bias = bias, back_fill = 'half_min')

hs311_tp <- hs311_tp %>% arrange(desc(score)) %>% select(compound, score)

df_names <- ct_details(hs311_tp$compound[1:10]) %>% select(preferredName, dtxsid)

df <- inner_join(hs311_tp, df_names, by = c("compound" = "dtxsid")) %>%
  relocate(preferredName, .after = compound) %>%
  left_join(., prod_volume, by = c("compound" = "dtxsid")) %>%
  relocate(volume_amount, .before = score) 

```

```{r}
#| label: tbl-scenario1
#| eval: true
#| include: true
#| echo: false
#| tbl-cap: "Scenario 1: Prioritization by compound, Top 10"
#| column: page

df %>% kable() %>% kable_styling(position = "center")
```

#### Scenario 2: River exposure to industrial waste stream

In scenario 2, a regulatory authority is taking samples from a river system that had been exposed to a inadvertent discharge of an industrial waste water. Similar to scenario 1, the source data contains individual sites with several compounds detected at each site in varying concentrations. Of interest is what is the immediate, acute threat, and what is the threat to long-term health for both the ecosystem and human health. The full code used to demonstrate this is available on the Github and the supplementary material.

For the first part of the analysis, the assessor chooses to prioritize oral, dermal, inhalation, and the acute aquatic toxicity as these pose an immediate threat to clean-up efforts as well as broad spectrum environmental threat to the river system. Several compounds are detected at multiple locations, with Site 'C' having the highest weighted mean score. In the top 25 samples (by score), three compounds (Pentachlorophenol, Chlorpyrifos, Caffeine) were detected at all four sites.

For the second part of the analysis, the assessor chose the inverse of the acute hazard assessment, choosing to focus on threats from cancer, genotoxic, endocrine, reproductive, developmental, and chronic aquatic toxicity, while also considering the long-term threat by incorporating persistence, bioaccumulation, and mobility characteristics. Similar to the acute prioritization, Site 'C' showed the highest weighted mean score. With the top 25 samples (by score), five compounds were detected at all four locations (Benzyl butyl phthalate, Pentachlorophenol, Bisphenol A, 1,4-Dichlorobenzene, Hydroquinone), offering several canidates for long-term monitoring efforts considering the endpoints assessed.

```{r}
#| label: scenario2_prep
#| eval: false
#| include: false
#| echo: false

sc2 <- ct_list(c('PRODWATER', 'EPAHFR', 'EPAHFRTABLE2', 'FRACFOCUS', 'SSWQS')) %>% distinct(dtxsid, .keep_all = T)
sc2 <- sc2 %>% arrange(desc(sourcesCount)) %>% slice_head(n = 50)

site <- list('A' = slice_sample(sc2, n = round(runif(1, min = 5, max = 20),0)) %>% select(dtxsid),
             'B' = slice_sample(sc2, n = round(runif(1, min = 5, max = 20),0)) %>% select(dtxsid),
             'C' = slice_sample(sc2, n = round(runif(1, min = 5, max = 20),0)) %>% select(dtxsid),
             'D' = slice_sample(sc2, n = round(runif(1, min = 5, max = 20),0)) %>% select(dtxsid))

site_df <- site %>%
  map_dfr(., as_tibble, .id = 'location') %>%
  rowwise() %>%
  mutate(conc = runif(1, min = 0, max = 100))

sc2_chem <- site_df %>% distinct(dtxsid) %>% as.list()

```

```{r}
#| label: scenario2_prep2
#| eval: true
#| include: false
#| echo: false

sc2 <- readRDS('sc2.Rds')
site_df <- readRDS('site_df.Rds')

sc2_chem <- hc_table(query = sc2_chem$dtxsid, save = F, archive = T, archive_string = 'sc2_')
```

```{r}
#| label: tbl-scenario2
#| eval: true
#| include: true
#| echo: false
#| column: page
#| tbl-cap: "Scenario 2: Acute vs Chronic Prioritization"
#| tbl-subcap: ["Acute prioritization by location", "Acute hazard prioritization by compound", "Chronic hazard prioritization by compound", "Chronic prioritization by location"]
#| layout-ncol: 4

#Acute 

sc2_bias <- hc_endpoint_coverage(table = sc2_chem, ID = 'compound', suffix = '_amount', filter = 0.1)

sc2_bias$weight[-c(1,2,3,9)] <- 0

sc2_bias <- sc2_bias %>% filter(weight == 1)

sc2_tp_acute <- tp_combined_score(table = sc2_chem, ID = 'compound', bias = sc2_bias) %>% left_join(., select(sc2, dtxsid, preferredName), by = c('compound' = 'dtxsid')) %>% select(compound, preferredName, score)

site_bias <- site_df %>% pivot_wider(., id_cols = location, names_from = dtxsid, values_from = conc) %>% hc_endpoint_coverage(., ID = 'location', filter = 0)

acute_df <- site_df %>% 
  pivot_wider(., id_cols = location, names_from = dtxsid, values_from = conc) %>%
  tp_combined_score(., ID = 'location', bias = site_bias) %>% 
  select(-score) %>% 
  pivot_longer(., cols = !location, names_to = 'dtxsid', values_to = 'conc_score') %>%
  left_join(., sc2_tp_acute, by = c('dtxsid' = 'compound')) %>% 
  rowwise() %>% 
  mutate(score = sum(c(conc_score, score))) %>% 
  select(-conc_score) %>% 
  arrange(desc(score)) %>% 
  filter(!is.na(preferredName)) %>% 
  head(n = 25)

acute_df %>% group_by(location) %>% summarize(count = n(), avg_score = weighted.mean(score, w = score/sum(score))) %>% 
  arrange(desc(avg_score), desc(count)) %>% kable()

acute_df %>% group_by(preferredName) %>% summarize(count = n(), avg_score = mean(score)) %>% 
  arrange(desc(count), desc(avg_score)) %>% kable()


#Chronic----

sc2_bias <- hc_endpoint_coverage(table = sc2_chem, ID = 'compound', suffix = '_amount', filter = 0.1)

sc2_bias$weight[-c(4,5,6, 7, 8, 10, 12, 13, 14)] <- 0

sc2_bias <- sc2_bias %>% filter(weight == 1)

sc2_tp_chronic <- tp_combined_score(table = sc2_chem, ID = 'compound', bias = sc2_bias) %>% left_join(., select(sc2, dtxsid, preferredName), by = c('compound' = 'dtxsid')) %>% select(compound, preferredName, score)

site_bias <- site_df %>% pivot_wider(., id_cols = location, names_from = dtxsid, values_from = conc) %>% hc_endpoint_coverage(., ID = 'location', filter = 0)

chronic_df <- site_df %>% 
  pivot_wider(., id_cols = location, names_from = dtxsid, values_from = conc) %>%
  tp_combined_score(., ID = 'location', bias = site_bias) %>% 
  select(-score) %>% 
  pivot_longer(., cols = !location, names_to = 'dtxsid', values_to = 'conc_score') %>%
  left_join(., sc2_tp_chronic, by = c('dtxsid' = 'compound')) %>% 
  rowwise() %>% 
  mutate(score = sum(c(conc_score, score))) %>% 
  select(-conc_score) %>% 
  arrange(desc(score)) %>%
  head(n = 25)

chronic_df %>%  group_by(preferredName) %>% summarize(count = n(), avg_score = mean(score)) %>% 
  arrange(desc(count), desc(avg_score)) %>% kable()

chronic_df %>% group_by(location) %>% summarize(count = n(), avg_score = weighted.mean(score, w = score/sum(score))) %>% 
  arrange(desc(avg_score), desc(count)) %>% kable()

```

## Comparisons to other relevant R packages

### `webchem`

`webchem` is a "R package to retrieve chemical information from the web..." and provides access to "a suite of web APIs to retrieve chemical information" from a variety of disparate databases. Some of the the databases (e.g.: ChemSpider) require a separate API token to access. Curation quality of these databases is not reported.

Comparatively, `ComptoxR` provides a single point of access to a variety of already curated and integrated databases under the 'umbrella' of CCD. Users can query one compound and retrieve results from upwards of 30 **DOUBLE CHECK** databases and aggregate results at their leisure.

Currently `ComptoxR` relies on `webchem` to pull GHS data, but aims to depreciate this dependency as internal efforts at US EPA continue to work towards hosting and curating GHS data.

`standartox`

### `ECOTOXr`

`ECOTOXr` allows for a local download and storage of the US EPA's 'ECOTOX' environmental database in a SQLite format for query. As of writing, ECOTOX does not have an API for querying this database.

ECOTOX is covered under the CCD 'umbrella' of databases and is thus covered under this package. `ComptoxR` does not natively store data automatically, but returned queries can be saved in a variety of R storage formats and recalled later.

### `toxpiR`

`toxpiR` is a native implementation of the Toxicological Priority Index (ToxPi) prioritization algorithm, and purports to offer more flexibility than the ToxPi GUI.

Inherently, the math behind the ToxPi algorithm is not hard to reproduce (a min-max normalization scheme), but the `toxpiR` package utilizes the `R6` reference class and may not be as easily accessible to all users. In comparison, the `tp` function made available through `ComptoxR` takes two data frame objects (a weighing table and a table holding the parent data) and performs the normalization scheme. We also offer the ability to back-fill data gaps with the minimum, mean, maximum (as supported by a meta-analysis @to_2018), as well as 50% of the lowest non-zero value of a given endpoint, and provide meta-statistics on the quality of data being analyzed.

## Open science

Given the open-source nature of this project, all source code is currently hosted on an US EPA Github, with future plans to submit to CRAN when development is stable. Code is licensed under the \[**INSERT**\] license.

## Further Development

Looking forward, we aim to continue to add new data sources. While available, but not currently built out as-of the writing of this paper is the bio-activity data sets from CCD. We also look to adding data endpoints such as product usage, product volume, as well as GHS data. Finally, we envision addition of other 'Hazard Comparison' endpoints to better suit risk-assessor needs.

## Conclusions

`ComptoxR` is a package that was designed to assist with retrieving high quality curated chemical data for various purposes.

##### Disclaimer

This article was supported in part by an appointment to the Research Participation Program at the Office of Research and Development, Center for Environmental Solutions and Emergency Response, U.S. Environmental Protection Agency, administered by the Oak Ridge Institute for Science and Education through an interagency agreement between the U.S. Department of Energy and EPA.The views expressed in this article are those of the author(s) and do not necessarily represent the views or the policies of the U.S. Environmental Protection Agency. EPA is distributing this information solely as a public service.

This R package is a compilation of information sourced from many databases and literature sources, including U.S. Federal and state sources and international bodies, which can save the user time by providing information in one location. The data are not fully reviewed by USEPA -- the user must apply judgment in use of the information. You should consult the original scientific paper or data source if possible. Reference herein to any specific commercial products, process, or service by trade name, trademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government. The views and opinions of the developers of the site expressed herein do not necessarily state or reflect those of the United States Government, and shall not be used for advertising or product endorsement purposes With respect to documents available from this server, neither the United States Government nor any of their employees, makes any warranty, express or implied, including the warranties of merchantability and fitness for a particular purpose, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights.

##### Acknowledgements

We are grateful to for their comments on the manuscript.

###### References
